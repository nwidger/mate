\chapter{CONCLUSIONS}
\label{CONCLUSIONS}

\section{Conclusions}

The results gathered from the benchmarks do not back up my original
thesis: the results indicate that the overhead of implementing DMP in
a Java-like programming language such as maTe is not lower than a
C-like programming language.  I no longer think it likely that such an
implementation can beat out the performance of DMP implemented as a
runtime-library for compiled languages such as C/C++.

% What was the average overhead for C/C++ versus maTe?

However, I still believe that implementing DMP inside a virtual
machine is still a sound idea.  On all but the most extreme DMP
parameter settings, the performance overhead seen in the benchmarks
was acceptable.  This is especially true if running the benchmarks
would uncover a bug in the implementation.  On longer-running
benchmarks, the acceptability may not hold.  Furthermore, there are
definitely advantages to not having to recompile a maTe program in
order to run with/without DMP enabled.  Being able to quickly run the
same program repeatedly using different DMP parameters makes it much
easier to find optimal parameters for a given benchmark and input
data.

I also conclude that implementing an efficient multithreaded virtual
machine is itself a difficult task, especially when starting with a
virtual machine that was initially designed to be only single
threaded.  Reducing thread contention when accessing global data
structures, especially the heap, was difficult.  Analyzing the results
was made more difficult due to the fact that in many of the benchmarks
the maTe virtual machine's performance worsened as more threads were
added.

It is also clear from the results that using different ownership table
depths was not particularly effective in reducing the amount of time
threads block due to ownership changes on most benchmarks.  There are
a number of possibilities for this result.  One is that the particular
set of benchmarks chosen did not benefit from different depths.
Another possibility is that because most of the benchmarks stored its
data in Table instances shared across threads, using any depth greater
than one would mean every write to a Table would cause all the
key/value pairs objects in the Table to change owner.  In benchmarks
that stores its data in a handful of global Tables, % (WHICH DID THAT?)
this would essentially serialize access to the table. % DID THAT ACTUALLY HAPPEN?

% Discuss attempt to implement Table using objects to try to allow
% more fine-grained ownership of Table fields.

I definitely found that the Table class, being the most complex native
class and also the only built-in data structure, was one of the most
difficult parts of the virtual machine to get working with DMP.

\section{Future Work}

Future work could include modifying the ownership table policy to
include an adaptive algorithm that attempts to learn the shared memory
profile of the maTe program and adjust the ownership of objects in an
attempt to increase the likelihood that a thread can access a given
object without needing to block.

Future work could also include making the maTe virtual machine more
efficient when run with many threads.  This could include
reimplementing the virtual machine's heap to allocate large blocks of
memory up front instead of calling $malloc$ for every allocation of a
virtual machine object.

As stated earlier, the current implementation runs the serial garbage
collector at the end of serial mode when the heap is at least $90\%$
full.  There may be better ways to integrate the garbage collector
with DMP.  Doing this while maintaining DMP's guarantee of
deterministic execution could be difficult, however.

Modify language to allow adding annotations to source code that help
virtual machine choose better DMP parameters.  For example, if a data
structure is known to be accessed only by a single thread, DMP checks
on that object could be skipped.  It's possible that static analysis
could be used to determine when such optimizations are possible.

Improve maTe compiler so that object fields are not repeatedly
accessed unnecessarily when they already exist on the frame's local
variable array or operand stack.  This could reduce the amount of
blocking performed by a thread and thus improve performance.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
